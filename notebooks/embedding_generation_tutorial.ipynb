{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3abf8055",
   "metadata": {},
   "source": [
    "To execute this notebook, you need to either\n",
    " - Download a pre-trained model\n",
    " - Train an example model by excecuting the model_training_tutorial.ipynb notebook\n",
    "\n",
    "In this tutorial we will learn to:\n",
    "- Load a previously trained model\n",
    "- Extract DeepPrint features from fingerprint images\n",
    "- Evaluate the performance of the extracted fixed-length representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282c13c",
   "metadata": {},
   "source": [
    "## Embedding extraction\n",
    "\n",
    "After training the model, we can extract the DeepPrint features for the fingerprint images. This is done by calling the `extract` method of the `DeepPrintExtractor` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f566250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model from /home/rs/21CS91R01/research/fixed-length-fingerprint-extractors/flx/pre_trained_model/best_model.pyt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rs/21CS91R01/anaconda3/envs/flx/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from flx.extractor.fixed_length_extractor import get_DeepPrint_Tex, get_DeepPrint_TexMinu, DeepPrintExtractor\n",
    "\n",
    "# Dimension and number of training subjects must be known to load the pre-trained model\n",
    "\n",
    "# To load the pre-trained model parameters use num_training_subjects=8000\n",
    "extractor: DeepPrintExtractor = get_DeepPrint_TexMinu(num_training_subjects=8000, num_dims=256)\n",
    "\n",
    "# To load the pre-trained model parameters use\n",
    "MODEL_DIR: str = os.path.abspath(\"/home/rs/21CS91R01/research/fixed-length-fingerprint-extractors/flx/pre_trained_model\") # Path to the directory containing the model parameters\n",
    "extractor.load_best_model(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b33e2f8",
   "metadata": {},
   "source": [
    "Now we need to specify the dataset, for which we want to extract the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbe661fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created IdentifierSet with 10 subjects and a total of 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:20<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m image_dataset: Dataset \u001b[38;5;241m=\u001b[39m Dataset(image_loader, image_loader\u001b[38;5;241m.\u001b[39mids)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# The second value is for the minutiae branch, which we do not have in this example\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m texture_embeddings, minutia_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mextractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/research/fixed-length-fingerprint-extractors/flx/extractor/fixed_length_extractor.py:62\u001b[0m, in \u001b[0;36mDeepPrintExtractor.extract\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: Dataset) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[EmbeddingLoader, EmbeddingLoader]:\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mextract_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/research/fixed-length-fingerprint-extractors/flx/extractor/extract_embeddings.py:46\u001b[0m, in \u001b[0;36mextract_embeddings\u001b[0;34m(model, fingerprint_dataset)\u001b[0m\n\u001b[1;32m     44\u001b[0m fp_imgs \u001b[38;5;241m=\u001b[39m vals\n\u001b[1;32m     45\u001b[0m fp_imgs: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m fp_imgs\u001b[38;5;241m.\u001b[39mto(get_device())\n\u001b[0;32m---> 46\u001b[0m output: DeepPrintOutput \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp_imgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m texture_embeddings\u001b[38;5;241m.\u001b[39mappend(_to_numpy(output\u001b[38;5;241m.\u001b[39mtexture_embeddings))\n\u001b[1;32m     49\u001b[0m minutia_embeddings\u001b[38;5;241m.\u001b[39mappend(_to_numpy(output\u001b[38;5;241m.\u001b[39mminutia_embeddings))\n",
      "File \u001b[0;32m~/anaconda3/envs/flx/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/flx/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/research/fixed-length-fingerprint-extractors/flx/models/deep_print_arch.py:329\u001b[0m, in \u001b[0;36mDeepPrint_TexMinu.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DeepPrintTrainingOutput(\n\u001b[1;32m    321\u001b[0m         minutia_logits\u001b[38;5;241m=\u001b[39mx_minutia_logits,\n\u001b[1;32m    322\u001b[0m         texture_logits\u001b[38;5;241m=\u001b[39mx_texture_logits,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    325\u001b[0m         texture_embeddings\u001b[38;5;241m=\u001b[39mx_texture_emb,\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 329\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m     x_texture_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtexture_branch\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[1;32m    331\u001b[0m     x_minutia \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminutia_stem\u001b[38;5;241m.\u001b[39mforward(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/flx/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/flx/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/research/fixed-length-fingerprint-extractors/flx/models/deep_print_arch.py:44\u001b[0m, in \u001b[0;36m_InceptionV4_Stem.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m DEEPPRINT_INPUT_SIZE\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m DEEPPRINT_INPUT_SIZE\n\u001b[1;32m     46\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from flx.data.dataset import *\n",
    "from flx.data.image_loader import SFingeLoader\n",
    "from flx.data.transformed_image_loader import TransformedImageLoader\n",
    "from flx.image_processing.binarization import LazilyAllocatedBinarizer\n",
    "from flx.data.image_helpers import pad_and_resize_to_deepprint_input_size\n",
    "\n",
    "# NOTE: If this does not work, enter the absolute path to the notebooks/example-dataset directory here! \n",
    "DATASET_PATH: str = os.path.abspath(\"example-dataset\")\n",
    "\n",
    "# We will use the SFingeLoader to load the images from the dataset\n",
    "image_loader = TransformedImageLoader(\n",
    "        images=SFingeLoader(DATASET_PATH),\n",
    "        poses=None,\n",
    "        transforms=[\n",
    "            LazilyAllocatedBinarizer(5.0),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "image_dataset: Dataset = Dataset(image_loader, image_loader.ids)\n",
    "\n",
    "# The second value is for the minutiae branch, which we do not have in this example\n",
    "texture_embeddings, minutia_embeddings = extractor.extract(image_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a423ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'minutia_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mminutia_embeddings\u001b[49m\u001b[38;5;241m.\u001b[39m_array)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'minutia_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "print(minutia_embeddings._array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f7d98",
   "metadata": {},
   "source": [
    "## Benchmarking\n",
    "\n",
    "To evaluate the embeddings, we want to run a benchmark on them. For this, we must first specify the type of benchmark, and which comparisons should be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e4e4c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 12686.94it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 17070.83it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 17712.43it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 16487.04it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 16213.00it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 16571.73it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 16777.22it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 16953.53it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 15857.48it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 16697.07it/s]\n"
     ]
    }
   ],
   "source": [
    "from flx.scripts.generate_benchmarks import create_verification_benchmark\n",
    "\n",
    "NUM_IMPRESSIONS_PER_SUBJECT = 10\n",
    "benchmark = create_verification_benchmark(\n",
    "    subjects=list(range(image_dataset.num_subjects)),\n",
    "    impressions_per_subject=list(range(NUM_IMPRESSIONS_PER_SUBJECT))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a37e9ef",
   "metadata": {},
   "source": [
    "Now we can run the benchmark. To do this, we must first specify the matcher (in our case cosine similarity of the embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f6bba7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'minutia_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedding_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbeddingLoader\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# We concatenate texture and minutia embedding vectors\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# embeddings = EmbeddingLoader.combine(texture_embeddings, minutia_embeddings)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m EmbeddingLoader\u001b[38;5;241m.\u001b[39mload(\u001b[43mminutia_embeddings\u001b[49m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(minutia_embeddings\u001b[38;5;241m.\u001b[39m_array)\n\u001b[1;32m     10\u001b[0m matcher \u001b[38;5;241m=\u001b[39m CosineSimilarityMatcher(EmbeddingLoader\u001b[38;5;241m.\u001b[39mload(texture_embeddings, minutia_embeddings))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'minutia_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "from flx.benchmarks.matchers import CosineSimilarityMatcher\n",
    "from flx.data.embedding_loader import EmbeddingLoader\n",
    "\n",
    "# We concatenate texture and minutia embedding vectors\n",
    "# embeddings = EmbeddingLoader.combine(texture_embeddings, minutia_embeddings)\n",
    "\n",
    "embeddings = EmbeddingLoader.load(minutia_embeddings)\n",
    "\n",
    "print(minutia_embeddings._array)\n",
    "matcher = CosineSimilarityMatcher(EmbeddingLoader.load(texture_embeddings, minutia_embeddings))\n",
    "\n",
    "results = benchmark.run(matcher)\n",
    "\n",
    "print(f\"Equal-Error-Rate: {results.get_equal_error_rate()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ee4287",
   "metadata": {},
   "source": [
    "To visualize the results, we can plot a DET curve. (Do not wonder if it is empty, probably the model is not trained enough. Take a look at the EER instead.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6f2f5e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'common_texification' from 'matplotlib.backends.backend_pgf' (/home/rs/21CS91R01/anaconda3/envs/flx/lib/python3.10/site-packages/matplotlib/backends/backend_pgf.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot_DET_curve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_verification_results\n\u001b[1;32m      3\u001b[0m figure_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDET_curve\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Lists are used to allow for multiple models to be plotted in the same figure\u001b[39;00m\n",
      "File \u001b[0;32m~/research/fixed-length-fingerprint-extractors/flx/visualization/plot_DET_curve.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdet_curve_plotting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDET\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DET\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mverification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VerificationResult\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01midentification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IdentificationResult\n",
      "File \u001b[0;32m~/research/fixed-length-fingerprint-extractors/flx/visualization/det_curve_plotting/DET.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m namedtuple\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtikzplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save \u001b[38;5;28;01mas\u001b[39;00m tikz_save\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m     30\u001b[0m __license__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHDA-OPEN-RESEARCH\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/flx/lib/python3.10/site-packages/tikzplotlib/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__about__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cleanfigure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clean_figure\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_save\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flavors, get_tikz_code, save\n\u001b[1;32m      7\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_tikz_code\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlavors\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/flx/lib/python3.10/site-packages/tikzplotlib/_save.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _axes\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _image \u001b[38;5;28;01mas\u001b[39;00m img\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _legend, _line2d, _patch, _path\n",
      "File \u001b[0;32m~/anaconda3/envs/flx/lib/python3.10/site-packages/tikzplotlib/_axes.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_pgf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     common_texification \u001b[38;5;28;01mas\u001b[39;00m mpl_common_texification,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _color\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_common_texification\u001b[39m(string):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Work around <https://github.com/matplotlib/matplotlib/issues/15493>\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'common_texification' from 'matplotlib.backends.backend_pgf' (/home/rs/21CS91R01/anaconda3/envs/flx/lib/python3.10/site-packages/matplotlib/backends/backend_pgf.py)"
     ]
    }
   ],
   "source": [
    "from flx.visualization.plot_DET_curve import plot_verification_results\n",
    "\n",
    "figure_path = \"DET_curve\"\n",
    "\n",
    "# Lists are used to allow for multiple models to be plotted in the same figure\n",
    "plot_verification_results(figure_path, results=[results], model_labels=[\"DeepPrint_TexMinu\"], plot_title=\"example-dataset - verification\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
