{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3abf8055",
   "metadata": {},
   "source": [
    "To execute this notebook, you need to either\n",
    " - Download a pre-trained model\n",
    " - Train an example model by excecuting the model_training_tutorial.ipynb notebook\n",
    "\n",
    "In this tutorial we will learn to:\n",
    "- Load a previously trained model\n",
    "- Extract DeepPrint features from fingerprint images\n",
    "- Evaluate the performance of the extracted fixed-length representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282c13c",
   "metadata": {},
   "source": [
    "## Embedding extraction\n",
    "\n",
    "After training the model, we can extract the DeepPrint features for the fingerprint images. This is done by calling the `extract` method of the `DeepPrintExtractor` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f566250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model from C:\\Users\\nis\\Downloads\\Alka\\fixed-length-fingerprint-extractors\\notebooks\\fvc2006db3_A_model\\best_model.pyt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from flx.extractor.fixed_length_extractor import get_DeepPrint_Tex, get_DeepPrint_TexMinu, DeepPrintExtractor\n",
    "\n",
    "# Dimension and number of training subjects must be known to load the pre-trained model\n",
    "\n",
    "# To load the pre-trained model parameters use num_training_subjects=8000\n",
    "extractor: DeepPrintExtractor = get_DeepPrint_TexMinu(num_training_subjects=140, num_dims=128)\n",
    "\n",
    "# To load the pre-trained model parameters use\n",
    "MODEL_DIR: str = os.path.abspath(r\"C:\\Users\\nis\\Downloads\\Alka\\fixed-length-fingerprint-extractors\\notebooks\\fvc2006db3_A_model\") # Path to the directory containing the model parameters\n",
    "extractor.load_best_model(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b33e2f8",
   "metadata": {},
   "source": [
    "Now we need to specify the dataset, for which we want to extract the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe661fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "alka\n",
      "Created IdentifierSet with 10 subjects and a total of 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:20<00:00,  5.15s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from flx.data.dataset import *\n",
    "from flx.data.image_loader import SFingeLoader\n",
    "from flx.data.transformed_image_loader import TransformedImageLoader\n",
    "from flx.image_processing.binarization import LazilyAllocatedBinarizer\n",
    "from flx.data.image_helpers import pad_and_resize_to_deepprint_input_size\n",
    "\n",
    "# NOTE: If this does not work, enter the absolute path to the notebooks/example-dataset directory here! \n",
    "DATASET_PATH: str = os.path.abspath(\"example-dataset\")\n",
    "\n",
    "# We will use the SFingeLoader to load the images from the dataset\n",
    "image_loader = TransformedImageLoader(\n",
    "        images=SFingeLoader(DATASET_PATH),\n",
    "        poses=None,\n",
    "        transforms=[\n",
    "            LazilyAllocatedBinarizer(5.0),\n",
    "            pad_and_resize_to_deepprint_input_size,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "image_dataset: Dataset = Dataset(image_loader, image_loader.ids)\n",
    "\n",
    "# The second value is for the minutiae branch, which we do not have in this example\n",
    "texture_embeddings, minutia_embeddings = extractor.extract(image_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16a423ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08521109  0.05031912 -0.03095857 ...  0.10988668 -0.00041138\n",
      "   0.09260689]\n",
      " [-0.08554287  0.05001848 -0.03129748 ...  0.109451   -0.00059758\n",
      "   0.09230988]\n",
      " [-0.08544277  0.0501082  -0.03120624 ...  0.10957261 -0.00054808\n",
      "   0.09239409]\n",
      " ...\n",
      " [-0.08554267  0.05002268 -0.03129241 ...  0.10947791 -0.00061655\n",
      "   0.09233475]\n",
      " [-0.08567694  0.04990215 -0.03143011 ...  0.10928711 -0.00069184\n",
      "   0.09220836]\n",
      " [-0.08551066  0.05004448 -0.03127202 ...  0.10951854 -0.00060559\n",
      "   0.09236255]]\n"
     ]
    }
   ],
   "source": [
    "print(minutia_embeddings._array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f7d98",
   "metadata": {},
   "source": [
    "## Benchmarking\n",
    "\n",
    "To evaluate the embeddings, we want to run a benchmark on them. For this, we must first specify the type of benchmark, and which comparisons should be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e4e4c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10003.11it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 9979.31it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from flx.scripts.generate_benchmarks import create_verification_benchmark\n",
    "\n",
    "NUM_IMPRESSIONS_PER_SUBJECT = 10\n",
    "benchmark = create_verification_benchmark(\n",
    "    subjects=list(range(image_dataset.num_subjects)),\n",
    "    impressions_per_subject=list(range(NUM_IMPRESSIONS_PER_SUBJECT))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a37e9ef",
   "metadata": {},
   "source": [
    "Now we can run the benchmark. To do this, we must first specify the matcher (in our case cosine similarity of the embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f6bba7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created IdentifierSet with 10 subjects and a total of 100 samples.\n",
      "Created IdentifierSet with 10 subjects and a total of 100 samples.\n",
      "Created IdentifierSet with 10 subjects and a total of 100 samples.\n",
      "Created IdentifierSet with 10 subjects and a total of 100 samples.\n",
      "Created IdentifierSet with 10 subjects and a total of 100 samples.\n",
      "Created IdentifierSet with 10 subjects and a total of 100 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1450/1450 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal-Error-Rate: 0.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from flx.benchmarks.matchers import CosineSimilarityMatcher\n",
    "from flx.data.embedding_loader import EmbeddingLoader\n",
    "\n",
    "# We concatenate texture and minutia embedding vectors\n",
    "embeddings = EmbeddingLoader.combine(texture_embeddings, minutia_embeddings)\n",
    "matcher = CosineSimilarityMatcher(EmbeddingLoader.combine(texture_embeddings, minutia_embeddings))\n",
    "\n",
    "results = benchmark.run(matcher)\n",
    "\n",
    "print(f\"Equal-Error-Rate: {results.get_equal_error_rate()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ee4287",
   "metadata": {},
   "source": [
    "To visualize the results, we can plot a DET curve. (Do not wonder if it is empty, probably the model is not trained enough. Take a look at the EER instead.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f2f5e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'common_texification' from 'matplotlib.backends.backend_pgf' (c:\\Users\\nis\\.conda\\envs\\flx\\lib\\site-packages\\matplotlib\\backends\\backend_pgf.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot_DET_curve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_verification_results\n\u001b[0;32m      3\u001b[0m figure_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDET_curve\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Lists are used to allow for multiple models to be plotted in the same figure\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\nis\\downloads\\alka\\fixed-length-fingerprint-extractors\\flx\\visualization\\plot_DET_curve.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdet_curve_plotting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDET\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DET\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mverification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VerificationResult\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchmarks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01midentification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IdentificationResult\n",
      "File \u001b[1;32mc:\\users\\nis\\downloads\\alka\\fixed-length-fingerprint-extractors\\flx\\visualization\\det_curve_plotting\\DET.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m namedtuple\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtikzplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save \u001b[38;5;28;01mas\u001b[39;00m tikz_save\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m     30\u001b[0m __license__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHDA-OPEN-RESEARCH\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nis\\.conda\\envs\\flx\\lib\\site-packages\\tikzplotlib\\__init__.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__about__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cleanfigure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clean_figure\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_save\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flavors, get_tikz_code, save\n\u001b[0;32m      7\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_tikz_code\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlavors\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\nis\\.conda\\envs\\flx\\lib\\site-packages\\tikzplotlib\\_save.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _axes\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _image \u001b[38;5;28;01mas\u001b[39;00m img\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _legend, _line2d, _patch, _path\n",
      "File \u001b[1;32mc:\\Users\\nis\\.conda\\envs\\flx\\lib\\site-packages\\tikzplotlib\\_axes.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_pgf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     common_texification \u001b[38;5;28;01mas\u001b[39;00m mpl_common_texification,\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _color\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_common_texification\u001b[39m(string):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Work around <https://github.com/matplotlib/matplotlib/issues/15493>\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'common_texification' from 'matplotlib.backends.backend_pgf' (c:\\Users\\nis\\.conda\\envs\\flx\\lib\\site-packages\\matplotlib\\backends\\backend_pgf.py)"
     ]
    }
   ],
   "source": [
    "from flx.visualization.plot_DET_curve import plot_verification_results\n",
    "\n",
    "figure_path = \"DET_curve\"\n",
    "\n",
    "# Lists are used to allow for multiple models to be plotted in the same figure\n",
    "plot_verification_results(figure_path, results=[results], model_labels=[\"DeepPrint_TexMinu\"], plot_title=\"example-dataset - verification\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
