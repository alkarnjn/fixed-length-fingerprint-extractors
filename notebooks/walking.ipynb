{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "96A2kqDDqBbY"
      },
      "outputs": [],
      "source": [
        "import numpy as np;\n",
        "import cv2;\n",
        "from scipy import ndimage;\n",
        "from scipy import signal\n",
        "\n",
        "def ridge_orient(im, gradientsigma, blocksigma, orientsmoothsigma):\n",
        "    rows,cols = im.shape;\n",
        "    #Calculate image gradients.\n",
        "    sze = np.fix(6*gradientsigma);\n",
        "    if np.remainder(sze,2) == 0:\n",
        "        sze = sze+1;\n",
        "        \n",
        "    gauss = cv2.getGaussianKernel(int(sze),gradientsigma);\n",
        "    f = gauss * gauss.T;\n",
        "    \n",
        "    fy,fx = np.gradient(f);     #Gradient of Gaussian\n",
        "    \n",
        "    #Gx = ndimage.convolve(np.double(im),fx);\n",
        "    #Gy = ndimage.convolve(np.double(im),fy);\n",
        "    \n",
        "    Gx = signal.convolve2d(im,fx,mode='same');    \n",
        "    Gy = signal.convolve2d(im,fy,mode='same');\n",
        "    \n",
        "    Gxx = np.power(Gx,2);\n",
        "    Gyy = np.power(Gy,2);\n",
        "    Gxy = Gx*Gy;\n",
        "    \n",
        "    #Now smooth the covariance data to perform a weighted summation of the data.    \n",
        "    \n",
        "    sze = np.fix(6*blocksigma);\n",
        "    \n",
        "    gauss = cv2.getGaussianKernel(int(sze),blocksigma);\n",
        "    f = gauss * gauss.T;\n",
        "    \n",
        "    Gxx = ndimage.convolve(Gxx,f);\n",
        "    Gyy = ndimage.convolve(Gyy,f);\n",
        "    Gxy = 2*ndimage.convolve(Gxy,f);\n",
        "    \n",
        "    # Analytic solution of principal direction\n",
        "    denom = np.sqrt(np.power(Gxy,2) + np.power((Gxx - Gyy),2)) + np.finfo(float).eps;\n",
        "    \n",
        "    sin2theta = Gxy/denom;            # Sine and cosine of doubled angles\n",
        "    cos2theta = (Gxx-Gyy)/denom;\n",
        "    \n",
        "    \n",
        "    if orientsmoothsigma:\n",
        "        sze = np.fix(6*orientsmoothsigma);\n",
        "        if np.remainder(sze,2) == 0:\n",
        "            sze = sze+1;    \n",
        "        gauss = cv2.getGaussianKernel(int(sze),orientsmoothsigma);\n",
        "        f = gauss * gauss.T;\n",
        "        cos2theta = ndimage.convolve(cos2theta,f); # Smoothed sine and cosine of\n",
        "        sin2theta = ndimage.convolve(sin2theta,f); # doubled angles\n",
        "    \n",
        "    orientim = np.pi/2 + np.arctan2(sin2theta,cos2theta)/2;\n",
        "    return(orientim);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HbB-UhyfqCvH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalise(img,mean,std):\n",
        "    normed = (img - np.mean(img))/(np.std(img));    \n",
        "    return(normed)\n",
        "    \n",
        "def ridge_segment(im,blksze,thresh):\n",
        "    \n",
        "    rows,cols = im.shape;    \n",
        "    \n",
        "    im = normalise(im,0,1);    # normalise to get zero mean and unit standard deviation\n",
        "    \n",
        "    \n",
        "    new_rows =  int(blksze * np.ceil((float(rows))/(float(blksze))))\n",
        "    new_cols =  int(blksze * np.ceil((float(cols))/(float(blksze))))\n",
        "    \n",
        "    padded_img = np.zeros((new_rows,new_cols));\n",
        "    stddevim = np.zeros((new_rows,new_cols));\n",
        "    \n",
        "    padded_img[0:rows][:,0:cols] = im;\n",
        "    \n",
        "    for i in range(0,new_rows,blksze):\n",
        "        for j in range(0,new_cols,blksze):\n",
        "            block = padded_img[i:i+blksze][:,j:j+blksze];\n",
        "            \n",
        "            stddevim[i:i+blksze][:,j:j+blksze] = np.std(block)*np.ones(block.shape)\n",
        "    \n",
        "    stddevim = stddevim[0:rows][:,0:cols]\n",
        "                    \n",
        "    mask = stddevim > thresh;\n",
        "    \n",
        "    mean_val = np.mean(im[mask]);\n",
        "    \n",
        "    std_val = np.std(im[mask]);\n",
        "    \n",
        "    normim = (im - mean_val)/(std_val);\n",
        "    \n",
        "    return(normim,mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mIm2c_XaqKgI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import numpy.matlib\n",
        "# from ridge_segment import ridge_segment\n",
        "# from ridge_orient import ridge_orient\n",
        "\n",
        "\n",
        "\n",
        "def walkonce(im, mask, dfim, start, step, Td):\n",
        "\tsp = []\n",
        "\tcurrent =0\n",
        "\tpath = np.array([start])\n",
        "\twhile True:\n",
        "\t\ttemp = path[current,:]\n",
        "\t\tori = dfim[int(temp[0]), int(temp[1])]\n",
        "\t\tcurrent = current + 1\n",
        "\t\tpath = np.concatenate([path, temp + step*(np.around([[-np.sin(ori), np.cos(ori)]]))], axis=0)\n",
        "\t\tif (any(path[current,:] < 1) or any((path[current,:] - im.shape) > 0) or not mask[int(path[current,0]),int(path[current,1])]):\n",
        "\t\t\tbreak\n",
        "\t\tcpath = path[0:current,:]\n",
        "\t\tdcpath = cpath - np.matmul(np.ones((cpath.shape[0],1)), np.array([path[current,:]]))\n",
        "\t\tsqart = np.sqrt(dcpath[:,0]**2 + dcpath[:,1]**2)\n",
        "\t\tsqart = np.transpose(sqart).reshape((1,-1))\n",
        "\t\tsqart = np.fliplr(sqart)\n",
        "\t\tindx = np.argwhere(sqart < Td)\n",
        "\t\tif min(indx.shape)==0:\n",
        "\t\t\tind = np.empty(shape=(0,0))\n",
        "\t\telse:\n",
        "\t\t\tind = sqart.shape[1] - indx[0][1]\n",
        "\t\tif ind.size !=0:\n",
        "\t\t\tif current == ind:\n",
        "\t\t\t\tsp = path[current,:]\n",
        "\t\t\telif (current - ind) <=11:\n",
        "\t\t\t\tsp =  np.around(np.sum(path[ind:current+1,:], axis=0)/(current - ind + 1))\n",
        "\t\t\tbreak\n",
        "\treturn sp\n",
        "\n",
        "def checkstable(im, mask, orientim, tempsp, step, Td, R):\n",
        "\tstable=0\n",
        "\ttempsp = np.array([tempsp])\n",
        "\t\n",
        "\tif min(tempsp.shape) !=0:\n",
        "\t\tstable=1\n",
        "\t\ttrystart = np.matmul(np.ones((4,1)), tempsp) + np.array([[0,-1], [-1,0], [0,1], [1,0]])*R\n",
        "\t\tfor j in range(0,4):\n",
        "\t\t\tif (any(trystart[j,:] < 1) or any((trystart[j,:] - im.shape) > 0) or not mask[int(trystart[j,0]),int(trystart[j,1])]):\n",
        "\t\t\t\tstable=0\n",
        "\t\t\t\tbreak\n",
        "\t\t\tnewsp = walkonce(im, mask, orientim, trystart[j,:], step, Td)\n",
        "\t\t\tnewsp = np.array([newsp])\n",
        "\t\t\tif min(newsp.shape) == 0 or np.linalg.norm(tempsp - newsp) > R:\n",
        "\t\t\t\tstable=0\n",
        "\t\t\t\tbreak\n",
        "\treturn stable\n",
        "\n",
        "\n",
        "def mergeneighbors(points, threshold):\n",
        "\n",
        "\tfor i in range(0,points.shape[0]-1):\n",
        "\t\tif points[i,0] == 0:\n",
        "\t\t\tcontinue\n",
        "\t\tpointi = points[i,:]\n",
        "\t\tfor j in range(i+1,points.shape[0]):\n",
        "\t\t\tif points[j,0] == 0:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tif (np.linalg.norm(points[i,:] - points[j,:]) < threshold):\n",
        "\t\t\t\tpointi = np.concatenate([pointi, points[j,:]], axis=0)\n",
        "\t\t\t\tpoints[j,:] = [0, 0]\n",
        "\t\tif len(pointi)>=2:\n",
        "\t\t\tpointi = pointi.reshape((-1,2))\n",
        "\t\ts = np.sum(pointi, axis=0)\n",
        "\t\tpoints[i,:] = np.around(np.array([[s[0], s[1]]])/pointi.shape[0])\n",
        "\tpoints = points[~np.all(points==0, axis=1)]\n",
        "\treturn points\n",
        "\n",
        "\n",
        "def walking(img_path):\n",
        "\timg = cv2.imread(img_path,0)\n",
        "\t#initializing the dictionary\n",
        "\tsps = {}\n",
        "\tsps['core'] = []\n",
        "\tsps['delta'] = []\n",
        "\n",
        "\tstep = 7\n",
        "\tn = 2\n",
        "\tTd = 2\n",
        "\tR = 16\n",
        "\n",
        "\tblksze = 16;\n",
        "\tthresh = 0.3;\n",
        "\tnormim, mask = ridge_segment(img,blksze,thresh);    \n",
        "\tmask[(mask.shape[0]//blksze)*blksze+1:mask.shape[0],:] = 0\n",
        "\tmask[:,(mask.shape[1]//blksze)*blksze+1:mask.shape[1]] = 0\n",
        "\n",
        "\n",
        "\torientim = ridge_orient(normim, 1, 3, 3)\n",
        "\torientim = np.pi - orientim\n",
        "\t\n",
        "\t#sampling starting point\n",
        "\n",
        "\tI,J = np.where(mask==1)\n",
        "\tedge0 = np.array([min(I),min(J)])\n",
        "\tedge1 = np.array([max(I),max(J)])\n",
        "\td = (edge1-edge0)//(n+1)\n",
        "\tsampled_rows = np.array(range(edge0[0]+d[0], edge0[0] + d[0]*n + 1,d[0]))    #If some error comes, consider +1 also\n",
        "\tsampled_cols = np.array(range(edge0[1]+d[1], edge0[1] + d[1]*n + 1,d[1]))\n",
        "\tsampled_points = np.transpose([[np.kron(sampled_rows, np.ones((1,n)))],[np.matlib.repmat(sampled_cols, 1, n)]])\n",
        "\tsampled_points = np.reshape(sampled_points,(4,2))\n",
        "\t\n",
        "\n",
        "\n",
        "\t#Detect Cores\n",
        "\tfor r in range(0,4):\n",
        "\t\tif len(sps['core']) != 0:\n",
        "\t\t\tbreak\n",
        "\t\tWDFc1 = 2.0*orientim + (r+1)*np.pi/2\n",
        "\t\tcore1 = np.array([[]])\n",
        "\t\tcore2 = np.array([[]])\n",
        "\t\tfor i in range(0,sampled_points.shape[0]):\n",
        "\t\t\tp = sampled_points[i,:]\n",
        "\t\t\tif (not mask[int(p[0]),int(p[1])]):\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tif min(core1.shape) == 0:\n",
        "\t\t\t\ttempsp = walkonce(img, mask, WDFc1, p, step, Td)\n",
        "\t\t\t\tif checkstable(img, mask, WDFc1, tempsp, step, Td, R):\n",
        "\t\t\t\t\tcore1 = tempsp\n",
        "\t\t\tif min(core2.shape) == 0:\n",
        "\t\t\t\ttempsp = walkonce(img, mask, WDFc1-np.pi, p, step, Td)\n",
        "\t\t\t\tif checkstable(img, mask, WDFc1-np.pi, tempsp, step, Td, R):\n",
        "\t\t\t\t\tcore2 = tempsp\n",
        "\t\tif min(core1.shape)==0:\n",
        "\t\t\tsps['core'] = np.array([core2])\n",
        "\t\telif min(core2.shape)==0:\n",
        "\t\t\tsps['core'] = np.array([core1])\n",
        "\t\telse:\n",
        "\t\t\tsps['core'] = np.concatenate([core1,core2], axis=0)\n",
        "\t\t\t\n",
        "\tprint(\"Core Points:\", sps['core'])\n",
        "\n",
        "\t#Detect Deltas\n",
        "\tfor r in range(0,4):\n",
        "\t\tif len(sps['delta']) != 0:\n",
        "\t\t\tbreak\n",
        "\t\tWDFd = -2.0*orientim + (r+1)*np.pi/2\n",
        "\t\tfor i in range(0,sampled_points.shape[0]):\n",
        "\t\t\tp = sampled_points[i,:]\n",
        "\t\t\tif (not mask[int(p[0]),int(p[1])]):\n",
        "\t\t\t\tcontinue\n",
        "\t\t\ttempsp = walkonce(img, mask, WDFd, p, step, Td)\n",
        "\t\t\tif checkstable(img, mask, WDFd, tempsp, step, Td, R):\n",
        "\t\t\t\tsps['delta'] = np.concatenate([sps['delta'],tempsp], axis=0)\n",
        "\t\tif len(sps['delta']) >=2:\n",
        "\t\t\tsps['delta'] = sps['delta'].reshape((-1,2))\n",
        "\n",
        "\tsps['core'] = np.array([sps['core']])\n",
        "\tsps['delta'] = np.array([sps['delta']])\n",
        "\t\n",
        "\tsps['core'] = sps['core'].reshape((-1,2))\n",
        "\tsps['delta'] = sps['delta'].reshape((-1,2))\n",
        "\n",
        "\tsps['core'] = np.fliplr(mergeneighbors(sps['core'],20))\n",
        "\tsps['delta'] = np.fliplr(mergeneighbors(sps['delta'],20))\n",
        "\treturn sps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Core Points: [[135. 173.]]\n"
          ]
        }
      ],
      "source": [
        "# # Pass an image and get core points\n",
        "# from pathlib import Path\n",
        "# cores=walking(Path('/home/mt0/22CS60R42/fixed-length-fingerprint-extractors/notebooks/example-dataset-png/2_5.png').as_posix())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Core Points: []\n",
            "Core Points: [[138. 170.]]\n",
            "Core Points: []\n",
            "Core Points: []\n",
            "Core Points: [152. 112. 116. 132.]\n",
            "Core Points: []\n",
            "Core Points: [[137. 166.]]\n",
            "Core Points: []\n",
            "Core Points: []\n",
            "Core Points: [[200. 150.]]\n",
            "Core Points: []\n",
            "Core Points: [[175. 144.]]\n",
            "Core Points: [246. 120. 166. 120.]\n",
            "Core Points: [152. 112. 116. 135.]\n",
            "Core Points: [[153. 132.]]\n",
            "Core Points: [[175. 151.]]\n",
            "Core Points: [[192. 142.]]\n",
            "Core Points: []\n",
            "Core Points: []\n",
            "Core Points: [[178. 143.]]\n",
            "Core Points: []\n",
            "Core Points: [244. 120. 166. 120.]\n",
            "Core Points: [[155. 134.]]\n",
            "Core Points: []\n",
            "Core Points: [[137. 168.]]\n",
            "Core Points: [[135. 173.]]\n",
            "Core Points: [[192. 140.]]\n",
            "Core Points: [[155. 136.]]\n",
            "Core Points: [[153. 132.]]\n",
            "Core Points: [[138. 170.]]\n",
            "Core Points: []\n",
            "Core Points: []\n",
            "Core Points: [[198. 144.]]\n",
            "Core Points: []\n",
            "Core Points: []\n",
            "Core Points: [[196. 143.]]\n",
            "Core Points: []\n",
            "Core Points: []\n",
            "Core Points: [245. 115. 162. 120.]\n",
            "Core Points: [150. 108. 119. 132.]\n",
            "Core Points: []\n",
            "Core Points: [245. 115. 166. 120.]\n",
            "Core Points: [[200. 142.]]\n",
            "Core Points: [[178. 148.]]\n",
            "Core Points: [[197. 147.]]\n",
            "Core Points: [[196. 142.]]\n",
            "Core Points: [[174. 145.]]\n",
            "Core Points: [250. 120. 172. 122.]\n",
            "Core Points: [[150. 140.]]\n",
            "Core Points: [[196. 142.]]\n",
            "Core Points: [[138. 170.]]\n",
            "Core Points: []\n",
            "Core Points: [[192. 142.]]\n",
            "Core Points: [249. 119. 166. 120.]\n",
            "Core Points: []\n",
            "Core Points: [[155. 134.]]\n",
            "Core Points: []\n",
            "Core Points: []\n",
            "Core Points: []\n",
            "Core Points: [154. 111. 120. 130.]\n",
            "Core Points: [152. 110. 119. 129.]\n",
            "Core Points: [150. 111. 117. 130.]\n",
            "Core Points: [[136. 167.]]\n",
            "Core Points: []\n",
            "Core Points: []\n",
            "Core Points: [150. 108. 119. 132.]\n",
            "Core Points: [[172. 146.]]\n",
            "Core Points: []\n",
            "Core Points: []\n",
            "Core Points: [[172. 147.]]\n",
            "Core Points: []\n",
            "Core Points: [[138. 170.]]\n",
            "Core Points: []\n",
            "Core Points: [[176. 150.]]\n",
            "Core Points: [242. 119. 163. 120.]\n",
            "Core Points: [150. 113. 118. 130.]\n",
            "Core Points: []\n",
            "Core Points: []\n",
            "Core Points: []\n",
            "Core Points: []\n",
            "Core Points: [[138. 170.]]\n",
            "Core Points: []\n",
            "Core Points: [[155. 134.]]\n",
            "Core Points: [[155. 134.]]\n",
            "Core Points: []\n",
            "Core Points: []\n",
            "Core Points: [245. 115. 166. 120.]\n",
            "Core Points: []\n",
            "Core Points: [[158. 130.]]\n",
            "Core Points: [[167. 144.]]\n",
            "Core Points: []\n",
            "Core Points: [244. 120. 170. 124.]\n",
            "Core Points: [150. 108. 120. 130.]\n",
            "Core Points: [[150. 136.]]\n",
            "Core Points: []\n",
            "Core Points: [[169. 140.]]\n",
            "Core Points: [[138. 170.]]\n",
            "Core Points: [154. 111. 119. 129.]\n",
            "Core Points: []\n",
            "Core Points: [242. 115. 161. 115.]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Save the core points to a text file\n",
        "def save_core_points_to_file(core_points, output_file_path):\n",
        "    with open(output_file_path, 'w') as file:\n",
        "        for point in core_points:\n",
        "            file.write(f\"{point[0]} {point[1]}\\n\")\n",
        "\n",
        "\n",
        "# Define the folder containing the images\n",
        "input_folder = '/home/mt0/22CS60R42/fixed-length-fingerprint-extractors/notebooks/example-dataset-png/'\n",
        "\n",
        "# Define the output folder for storing core point text files\n",
        "output_folder = '/home/mt0/22CS60R42/fixed-length-fingerprint-extractors/notebooks/walking_core_points'\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Iterate over each image file in the folder\n",
        "for image_file in Path(input_folder).glob('*.png'):\n",
        "    # Get core points for the current image\n",
        "    cores = walking(image_file.as_posix())\n",
        "\n",
        "    # Prepare the output file path\n",
        "    output_file_path = Path(output_folder) / f'{image_file.stem}.txt'\n",
        "\n",
        "    # Write the core points to the output text file\n",
        "    save_core_points_to_file(cores['core'], output_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
