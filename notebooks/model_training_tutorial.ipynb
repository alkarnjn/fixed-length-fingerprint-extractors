{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f0c027",
   "metadata": {},
   "source": [
    "In this tutorial we will learn to:\n",
    "- Instantiate a DeepPrintExtractor\n",
    "- Prepare a training dataset\n",
    "- Train a DeepPrintExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3b5048",
   "metadata": {},
   "source": [
    "## Instantiate a DeepPrintExtractor\n",
    "\n",
    "This package implements a number of variants of the DeepPrint architecture. The wrapper class for all these variants is called `DeepPrintExtractor`.\n",
    "It has a `fit` method to train (and save) the model as well as an `extract` method to extract the DeepPrint features for fingerprint images. \n",
    "\n",
    "You can also try to implement your own models, but currently this is not directly supported by the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cdc3357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created IdentifierSet with 1 subjects and a total of 1 samples.\n"
     ]
    }
   ],
   "source": [
    "from flx.data.dataset import IdentifierSet, Identifier\n",
    "from flx.extractor.fixed_length_extractor import get_DeepPrint_TexMinu,get_DeepPrint_Minu,get_DeepPrint_LocTex, DeepPrintExtractor\n",
    "\n",
    "# We will use the example dataset with 10 subjects and 10 impression per subject\n",
    "training_ids: IdentifierSet = IdentifierSet([Identifier(i, j) for i in range(1) for j in range(1)])\n",
    "\n",
    "# We choose a dimension of 512 for the fixed-length representation (TexMinu has two outputs num_dims)\n",
    "extractor: DeepPrintExtractor = get_DeepPrint_TexMinu(num_training_subjects=training_ids.num_subjects, num_dims=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0ba71af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<flx.data.dataset.IdentifierSet at 0x1e6e7947b50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9687ae",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Instantiating the model was easy. To train it, first we will load the training data (see the [data tutorial](./dataset_tutorial.ipynb) for how to implement your own dataset).\n",
    "\n",
    "Besides the fingerprint images, we also need a mapping from subjects to integer labels (for pytorch). For some variants we also need minutiae data. To see how a more complex dataset can be loaded, have a look at `flx/setup/datasets.py`.\n",
    "\n",
    "Finally, we call the `fit` method, which trains the model and saves it to the specified path.\n",
    "\n",
    "There is also the option to add a validation set, which will be used to evaluate the embeddings during training. This is useful to monitor the training progress and to avoid overfitting.\n",
    "In this example we will not use a validation set for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf461144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileDataset with root_dir '/home/mt0/22CS60R42/fixed-length-fingerprint-extractors/flx/data/iso_encoder_decoder/isoTemplate' is empty. No files with extension .png found.\n",
      "Created IdentifierSet with 0 subjects and a total of 0 samples.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The identifiers in the dataset must be a subset of the identifiers in the data loader!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 28\u001b[0m\n\u001b[1;32m     18\u001b[0m image_loader \u001b[38;5;241m=\u001b[39m TransformedImageLoader(\n\u001b[1;32m     19\u001b[0m         images\u001b[38;5;241m=\u001b[39mSFingeLoader(DATASET_DIR),\n\u001b[1;32m     20\u001b[0m         poses\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m         ],\n\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# print(training_ids.num_subjects)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m image_dataset \u001b[38;5;241m=\u001b[39m Dataset(image_loader, training_ids)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# For pytorch, we need to map the subjects to integer labels from [0 ... num_subjects-1]\u001b[39;00m\n\u001b[1;32m     31\u001b[0m label_dataset \u001b[38;5;241m=\u001b[39m Dataset(LabelIndex(training_ids), training_ids)\n",
      "File \u001b[0;32m~/fixed-length-fingerprint-extractors/flx/data/dataset.py:203\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, data_loader, identifier_set)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader \u001b[38;5;241m=\u001b[39m data_loader\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data_loader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m identifier_set \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m data_loader\u001b[38;5;241m.\u001b[39mids:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe identifiers in the dataset must be a subset of the identifiers in the data loader!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    205\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The identifiers in the dataset must be a subset of the identifiers in the data loader!"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch \n",
    "\n",
    "from flx.data.dataset import *\n",
    "from flx.data.image_loader import SFingeLoader\n",
    "from flx.data.minutia_map_loader import SFingeMinutiaMapLoader\n",
    "from flx.data.label_index import LabelIndex\n",
    "from flx.data.transformed_image_loader import TransformedImageLoader\n",
    "from flx.image_processing.binarization import LazilyAllocatedBinarizer\n",
    "from flx.data.image_helpers import pad_and_resize_to_deepprint_input_size\n",
    "\n",
    "# NOTE: If this does not work, enter the absolute paths manually here! \n",
    "DATASET_DIR: str = os.path.abspath(r\"/home/mt0/22CS60R42/fixed-length-fingerprint-extractors/flx/data/iso_encoder_decoder/isoTemplate\")\n",
    "MODEL_OUTDIR: str = os.path.abspath(r\"/home/mt0/22CS60R42/fixed-length-fingerprint-extractors/notebooks/example-m\")\n",
    "\n",
    "# We will use the SFingeLoader to load the images from the dataset\n",
    "image_loader = TransformedImageLoader(\n",
    "        images=SFingeLoader(DATASET_DIR),\n",
    "        poses=None,\n",
    "        transforms=[\n",
    "            LazilyAllocatedBinarizer(5.0),\n",
    "            pad_and_resize_to_deepprint_input_size,\n",
    "        ],\n",
    "    )\n",
    "# print(training_ids.num_subjects)\n",
    "\n",
    "image_dataset = Dataset(image_loader, training_ids)\n",
    "\n",
    "# For pytorch, we need to map the subjects to integer labels from [0 ... num_subjects-1]\n",
    "label_dataset = Dataset(LabelIndex(training_ids), training_ids)\n",
    "\n",
    "minutia_maps_dataset = Dataset(SFingeMinutiaMapLoader(DATASET_DIR), training_ids)\n",
    "print(\"alka\")\n",
    "extractor.fit(\n",
    "    fingerprints=image_dataset,\n",
    "    minutia_maps=minutia_maps_dataset,\n",
    "    labels=label_dataset,\n",
    "    validation_fingerprints=None,\n",
    "    validation_benchmark=None,\n",
    "    num_epochs=50,\n",
    "    out_dir=MODEL_OUTDIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ee7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biometrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
